<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assistant Vocal iPhone Style Ultra-Rapide</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://unpkg.com/lucide@latest/dist/umd/lucide.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', '-apple-system', 'BlinkMacSystemFont', 'Segoe UI', 'Roboto', 'sans-serif'],
                    },
                    borderRadius: { '4xl': '2rem', '5xl': '2.5rem' },
                    keyframes: {
                        pulse: {
                            '0%, 100%': { boxShadow: '0 0 0 0 rgba(74, 222, 128, 0.7)' },
                            '70%': { boxShadow: '0 0 0 10px rgba(74, 222, 128, 0)' },
                        },
                        'tts-pulse': {
                            '0%, 100%': { boxShadow: '0 0 0 0 rgba(168, 85, 247, 0.7)' },
                            '70%': { boxShadow: '0 0 0 10px rgba(168, 85, 247, 0)' },
                        },
                        'interrupt-flash': {
                            '0%': { boxShadow: '0 0 0 0 rgba(239, 68, 68, 0.8)' },
                            '50%': { boxShadow: '0 0 0 15px rgba(239, 68, 68, 0.4)' },
                            '100%': { boxShadow: '0 0 0 0 rgba(239, 68, 68, 0)' },
                        },
                        'processing-spin': {
                            '0%': { transform: 'rotate(0deg)' },
                            '100%': { transform: 'rotate(360deg)' },
                        },
                    },
                    animation: {
                        pulse: 'pulse 2s infinite',
                        'tts-pulse': 'tts-pulse 1.5s infinite',
                        'interrupt-flash': 'interrupt-flash 0.5s ease-out',
                        'processing-spin': 'processing-spin 1s linear infinite',
                    },
                },
            },
        }
    </script>
    <style>
        ::-webkit-scrollbar { width: 4px; }
        ::-webkit-scrollbar-track { background: rgba(255,255,255,0.1); border-radius: 10px; }
        ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.3); border-radius: 10px; }

        #toggleButton {
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            transform-origin: center;
        }
        #toggleButton:active { transform: scale(0.95); }
        #toggleButton:disabled { transform: scale(1); opacity: 0.5; }
    </style>
</head>
<body class="bg-gradient-to-br from-[#1e3a8a] to-[#3730a3] min-h-screen flex items-center justify-center font-sans text-white overflow-hidden">

    <div class="w-full h-full bg-gradient-to-br from-[#1e3c72]/80 to-[#2a5298]/80 relative flex flex-col">

        <div class="fixed top-0 left-0 w-full z-20">
            <div class="flex justify-between items-center px-5 py-3 text-white text-sm font-semibold">
                <button id="conversationToggle" class="p-2 rounded-lg bg-white/10 hover:bg-white/20 transition-colors">
                     <i data-lucide="message-square-text" class="w-5 h-5"></i>
                </button>
                <div id="time" class="font-bold">9:41</div>
                <button id="drawerToggle" class="p-2 rounded-lg bg-white/10 hover:bg-white/20 transition-colors">
                    <i data-lucide="sliders-horizontal" class="w-5 h-5"></i>
                </button>
            </div>
        </div>

        <div class="flex-1 flex flex-col justify-center items-center px-5 pt-16 pb-48">
            <div class="relative flex-shrink-0 text-center">
                <div id="voice-circle" class="w-[200px] h-[200px] rounded-full mx-auto mb-2.5 flex items-center justify-center text-6xl transition-all duration-300 bg-white/10 backdrop-blur-xl border-2 border-white/20">
                    <i data-lucide="power-off" class="w-16 h-16"></i>
                </div>
                <div id="status-text" class="text-center text-white text-lg font-medium">Pr√™t √† d√©marrer</div>
                <div id="interrupt-indicator" class="absolute -bottom-8 left-1/2 -translate-x-1/2 bg-red-500/80 text-white px-4 py-2 rounded-full text-xs opacity-0 transition-opacity duration-300">Interruption !</div>
                <div id="processing-indicator" class="absolute -bottom-16 left-1/2 -translate-x-1/2 bg-blue-500/80 text-white px-4 py-2 rounded-full text-xs opacity-0 transition-opacity duration-300">‚ö° Traitement...</div>
            </div>
        </div>

        <div class="fixed bottom-0 left-0 w-full z-20 p-4 bg-gradient-to-t from-[#1e3a8a] to-transparent">
             <div class="max-w-md mx-auto space-y-3">
                <button id="toggleButton" class="w-full py-4 rounded-2xl font-semibold text-base transition-all backdrop-blur-xl bg-green-500/80 text-white disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2">
                    <i data-lucide="mic" id="toggleIconEl"></i>
                    <span id="toggleText">D√©marrer</span>
                </button>

                <div id="modeButtons" class="flex justify-center items-center gap-2">
                    <button id="modeContinu" class="flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-green-500/80 text-white">
                        üîÑ Continu
                    </button>
                    <button id="modePushToTalk" class="flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-white/20 text-white/70 hover:bg-white/30">
                        üé§ Push-to-Talk
                    </button>
                </div>

                <div class="flex gap-2">
                    <input type="text" id="text-input" placeholder="Envoyer un message..." class="flex-1 bg-white/10 border border-white/20 rounded-xl px-4 py-3 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15">
                    <button id="send-button" class="p-3 bg-green-500/80 rounded-xl text-white hover:bg-green-500/100 transition-colors">
                         <i data-lucide="send-horizontal" class="w-6 h-6"></i>
                    </button>
                </div>

                <!-- Legacy iOS controls -->
                <div id="legacyControls" class="hidden space-y-2">
                    <input type="file" id="legacyAudioInput" accept="audio/*;capture=microphone" class="hidden">
                    <button id="legacyRecordBtn" class="w-full py-3 rounded-xl font-semibold bg-blue-500/80 text-white">
                        üéôÔ∏è Enregistrer (iOS ancien)
                    </button>
                    <div class="text-xs text-white/70">
                        Sur les anciens iPhone/iPad, utilisez ce bouton pour enregistrer, puis je transcris et je r√©ponds.
                    </div>
                </div>
            </div>
        </div>
    </div>

    <audio id="ttsAudio" style="display: none;" preload="auto" playsinline></audio>

    <div id="conversationDrawer" class="fixed inset-y-0 left-0 z-50 w-full sm:w-96 bg-gradient-to-b from-[#19356d] to-[#26488b] shadow-xl transform -translate-x-full transition-transform duration-300 ease-in-out flex flex-col">
        <div class="flex items-center justify-between p-4 border-b border-white/20 flex-shrink-0">
            <h2 class="text-white text-lg font-semibold">üí¨ Conversation</h2>
            <button id="conversationDrawerClose" class="text-white/70 hover:text-white transition-colors">
                 <i data-lucide="x" class="w-6 h-6"></i>
            </button>
        </div>
        <div id="conversationHistory" class="p-4 overflow-y-auto flex-1">
            <div class="text-white/60 text-center italic mt-10">
                L'historique de la conversation appara√Ætra ici...
            </div>
        </div>
    </div>

    <div id="settingsDrawer" class="fixed inset-y-0 right-0 z-50 w-full sm:w-96 bg-gradient-to-b from-[#19356d] to-[#26488b] shadow-xl transform translate-x-full transition-transform duration-300 ease-in-out flex flex-col">
        <div class="flex items-center justify-between p-4 border-b border-white/20 flex-shrink-0">
            <h2 class="text-white text-lg font-semibold">‚öôÔ∏è Panneau de contr√¥le</h2>
            <button id="settingsDrawerClose" class="text-white/70 hover:text-white transition-colors">
                <i data-lucide="x" class="w-6 h-6"></i>
            </button>
        </div>
        <div class="p-4 space-y-4 overflow-y-auto flex-1">
            <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">üõ†Ô∏è Param√®tres</h3>
                <input type="password" id="drawerGroqKey" placeholder="Cl√© API Groq (STT)" class="w-full bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15 mb-3">
                <input type="password" id="drawerOpenaiKey" placeholder="Cl√© API OpenAI (LLM)" class="w-full bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15 mb-3">
                <div class="grid grid-cols-2 gap-3 text-sm mt-3">
                    <label class="flex items-center gap-2 cursor-pointer"><input type="checkbox" id="drawerAutoSpeak" class="accent-green-400"> Auto TTS</label>
                    <label class="flex items-center gap-2 cursor-pointer"><input type="checkbox" id="drawerAllowInterrupt" class="accent-green-400"> Interruption</label>
                </div>
                <select id="drawerVoiceSelect" class="w-full mt-3 bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm appearance-none">
                    <option value="fr-FR-DeniseNeural">Voix: Denise</option>
                    <option value="fr-FR-EloiseNeural">Voix: Eloise</option>
                    <option value="fr-FR-FabriceNeural">Voix: Fabrice</option>
                    <option value="fr-FR-HenriNeural">Voix: Henri</option>
                </select>
            </div>
             <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">‚ö° Actions</h3>
                <div class="space-y-2">
                    <button id="drawerClearCache" class="w-full flex items-center justify-center gap-2 py-2 bg-red-500/80 hover:bg-red-500 rounded-lg text-white text-sm transition-colors"><i data-lucide="trash-2" class="w-4 h-4"></i> Vider le cache</button>
                    <button id="drawerExportConversation" class="w-full flex items-center justify-center gap-2 py-2 bg-blue-500/80 hover:bg-blue-500 rounded-lg text-white text-sm transition-colors"><i data-lucide="download" class="w-4 h-4"></i> Exporter</button>
                </div>
            </div>
            <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">üìù Log de d√©bogage</h3>
                <div id="drawerDebug" class="bg-black/20 rounded-lg p-3 text-xs text-white/70 h-48 overflow-y-auto">
                    <div>‚ö° Syst√®me pr√™t...</div>
                </div>
            </div>
        </div>
    </div>

    <div id="drawerOverlay" class="fixed inset-0 bg-black/50 z-40 opacity-0 pointer-events-none transition-opacity duration-300"></div>
    <div id="mobileConsole" class="fixed top-20 right-4 w-80 h-64 bg-black/90 text-green-400 text-xs p-2 rounded-lg z-50 overflow-y-auto font-mono hidden">
        <div class="flex justify-between items-center mb-2">
            <span>üì± Debug Console</span>
            <button onclick="document.getElementById('mobileConsole').classList.add('hidden')" class="text-red-400">‚úï</button>
        </div>
        <div id="mobileConsoleContent"></div>
    </div>

    <!-- IMPORTANT: on ne charge pas ort/vad en <script> global.
         Le script moderne les chargera dynamiquement si support√©. -->

    <!-- Script MODERNE (modules) pour navigateurs r√©cents -->
    <script type="module">
    // =============================================
    // üöÄ MODERN PIPELINE (navigateur r√©cent)
    // =============================================

    // Dynamically load VAD only if needed
    async function loadScript(src) {
        return new Promise((resolve, reject) => {
            const s = document.createElement('script');
            s.src = src;
            s.onload = resolve;
            s.onerror = () => reject(new Error('Failed to load ' + src));
            document.head.appendChild(s);
        });
    }
    async function ensureVadLoaded() {
        if (window.vad) return;
        await loadScript('https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js');
    }

    // =============================================
    // DOM & STATE
    // =============================================
    let myVad = null;
    let conversationHistory = [];
    let isPlaying = false;
    let isProcessingTTS = false;
    let pipelineActive = false;
    let generationWorkers = [];
    let readyAudioBuffer = new Map();
    let lastPlayedReflection = "";
    let recordingMode = 'continu';
    let isPushToTalkRecording = false;
    let isContinuRecording = false;
    let mediaRecorder, recordedChunks = [];
    const transcriptionCache = new Map();
    const ttsCache = new Map();
    const MAX_CACHE_SIZE = 50;
    const MAX_BUFFER_SIZE = 3;
    const baseCircleClasses = "w-[200px] h-[200px] rounded-full mx-auto mb-2.5 flex items-center justify-center text-6xl transition-all duration-300 backdrop-blur-xl";
    window.audioInitialized = false;

    let toggleButton, toggleIconEl, toggleText, voiceCircle, statusText, ttsAudio, interruptIndicator, processingIndicator, textInput, sendButton;
    let modeContinu, modePushToTalk, modeButtons;
    let conversationDrawer, conversationHistoryEl, settingsDrawer, drawerOverlay;
    let drawerGroqKey, drawerOpenaiKey, drawerAutoSpeak, drawerAllowInterrupt, drawerVoiceSelect, drawerDebug;
    let legacyControls, legacyAudioInput, legacyRecordBtn;

    const SIMPLE_REFLECTIONS = ["Ah oui, je vois...", "D'accord, tr√®s bien...", "OK, je comprends...", "Hmm, int√©ressant...", "Oui, effectivement...", "Ah, parfait...", "Tr√®s bien...", "Laissez-moi voir...", "Bien s√ªr...", "Oui, d'accord...", "Je comprends bien...", "Oui, tout √† fait..."];
    let reflectionAudios = new Map();
    let isPlayingReflection = false;

    function log(message, type = 'info') {
        const timestamp = new Date().toLocaleTimeString();
        const emoji = type === 'success' ? '‚úÖ' : type === 'error' ? '‚ùå' : type === 'warning' ? '‚ö†Ô∏è' : '‚ö°';
        const logMessage = `${timestamp} ${emoji} ${message}`;
        console.log(logMessage);
        if (drawerDebug) {
            const newLine = document.createElement('div');
            newLine.textContent = logMessage;
            const typeClass = { error: 'text-red-300', success: 'text-green-300', warning: 'text-yellow-300' };
            newLine.className = typeClass[type] || '';
            drawerDebug.insertBefore(newLine, drawerDebug.firstChild);
            while (drawerDebug.children.length > 50) drawerDebug.removeChild(drawerDebug.lastChild);
        }
    }

    async function initializeAudioContextForIOS() {
        if (window.audioInitialized) return true;
        try {
            const silentAudio = new Audio('data:audio/wav;base64,UklGRigAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA=');
            silentAudio.playsinline = true;
            await silentAudio.play();
            silentAudio.pause();
            const AudioCtx = window.AudioContext || window.webkitAudioContext;
            const ctx = new AudioCtx();
            await ctx.resume();
            log('‚úÖ Audio iOS initialis√©', 'success');
            window.audioInitialized = true;
            return true;
        } catch (error) {
            log('‚ö†Ô∏è Initialisation audio iOS √©chou√©e. Interaction requise.', 'warning');
            return false;
        }
    }

    function updateStatus(text, iconName, stateClass) {
        if (!statusText || !voiceCircle) return;
        statusText.textContent = text;
        voiceCircle.innerHTML = `<i data-lucide="${iconName}" class="w-16 h-16 ${stateClass === 'processing' ? 'animate-spin' : ''}"></i>`;
        processingIndicator?.classList.toggle('opacity-100', stateClass === 'processing');
        let stateClasses = "";
        switch (stateClass) {
            case "listening": stateClasses = "bg-green-400/20 border-2 border-green-400/40 animate-pulse"; break;
            case "speaking": stateClasses = "bg-green-600/30 border-2 border-green-600/50"; break;
            case "processing": stateClasses = "bg-amber-400/20 border-2 border-amber-400/40"; break;
            case "tts-playing": stateClasses = "bg-purple-500/20 border-2 border-purple-500/40 animate-tts-pulse"; break;
            case "interrupted": stateClasses = "bg-red-500/20 border-2 border-red-500/40 animate-interrupt-flash"; break;
            default: stateClasses = "bg-white/10 border-2 border-white/20";
        }
        voiceCircle.className = `${baseCircleClasses} ${stateClasses}`;
        lucide.createIcons();
    }

    function updateButtonState() {
        if (!toggleButton || !toggleIconEl || !toggleText) return;
        toggleButton.disabled = recordingMode === 'continu' && (isPlaying || isProcessingTTS);

        if (recordingMode === 'push-to-talk') {
            const baseClass = "w-full py-4 rounded-2xl font-semibold text-base transition-all backdrop-blur-xl text-white flex items-center justify-center gap-2";
            if (isPushToTalkRecording) {
                toggleButton.className = `${baseClass} bg-red-500/80 hover:bg-red-600/80 animate-pulse`;
                toggleIconEl.setAttribute('data-lucide', 'square');
                toggleText.textContent = 'Envoyer';
            } else if (isPlaying || isProcessingTTS) {
                toggleButton.className = `${baseClass} bg-orange-500/80 hover:bg-orange-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'square');
                toggleText.textContent = 'Interrompre';
            } else {
                toggleButton.className = `${baseClass} bg-blue-500/80 hover:bg-blue-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'mic');
                toggleText.textContent = 'Maintenir & Parler';
            }
        } else {
            const baseClass = "w-full py-4 rounded-2xl font-semibold text-base transition-all backdrop-blur-xl text-white disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2";
            if (isContinuRecording) {
                toggleButton.className = `${baseClass} bg-red-500/80 hover:bg-red-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'mic-off');
                toggleText.textContent = 'Arr√™ter';
            } else {
                toggleButton.className = `${baseClass} bg-green-500/80 hover:bg-green-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'mic');
                toggleText.textContent = 'D√©marrer';
            }
        }
        lucide.createIcons();
    }

    function updateModeButtons() {
        if (recordingMode === 'continu') {
            modeContinu.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-green-500/80 text-white";
            modePushToTalk.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-white/20 text-white/70 hover:bg-white/30";
        } else {
            modeContinu.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-white/20 text-white/70 hover:bg-white/30";
            modePushToTalk.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-blue-500/80 text-white";
        }
    }

    async function requestMicrophonePermission() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
            log('Permission microphone accord√©e', 'success');
            return true;
        } catch (error) {
            log('Permission microphone refus√©e.', 'error');
            alert('Autorisez le micro pour utiliser l‚Äôassistant vocal.');
            return false;
        }
    }

    async function toggleMasterRecording() {
        if (isContinuRecording || isPushToTalkRecording) {
            await stopAllRecording();
        } else {
            const hasPermission = await requestMicrophonePermission();
            if (!hasPermission) return;
            if (recordingMode === 'continu') await startContinuRecording();
            else await startPushToTalkRecording();
        }
    }

    async function togglePushToTalk() {
        if (isPlaying || isProcessingTTS) {
            interruptTTS();
            await new Promise(resolve => setTimeout(resolve, 100));
        }
        if (isPushToTalkRecording) {
            await stopPushToTalkRecording();
        } else {
            const hasPermission = await requestMicrophonePermission();
            if (hasPermission) await startPushToTalkRecording();
        }
    }

    async function startContinuRecording() {
        if (!drawerGroqKey.value.trim() || !drawerOpenaiKey.value.trim()) {
            alert('Veuillez configurer vos cl√©s API dans le panneau de contr√¥le.');
            return;
        }
        if (/iPad|iPhone|iPod/.test(navigator.userAgent)) {
            await initializeAudioContextForIOS();
        }
        await ensureVadLoaded();

        toggleButton.disabled = true;
        updateStatus("Initialisation...", "loader-circle", "processing");

        try {
            await preGenerateSimpleReflections();
            myVad = await vad.MicVAD.new({
                positiveSpeechThreshold: 0.8, minSpeechFrames: 6, preSpeechPadFrames: 1, redemptionFrames: 10,
                onSpeechStart: () => {
                    log("Parole d√©tect√©e", 'success');
                    if (!interruptTTS()) updateStatus("Vous parlez...", "mic", "speaking");
                },
                onSpeechEnd: (audio) => {
                    log(`Fin de parole`, 'info');
                    playRandomReflection();
                    if (!isProcessingTTS && audio.length > 100) transcribeAudioUltraFast(audio);
                    else if (myVad) updateStatus("En √©coute...", "mic", "listening");
                },
            });
            myVad.start();
            isContinuRecording = true;
            updateButtonState();
            updateStatus("En √©coute...", "mic", "listening");
            log("üé§ Mode Continu d√©marr√© !", 'success');
        } catch (error) {
            log(`Erreur VAD: ${error.message}`, 'error');
            updateStatus("Erreur VAD", "alert-circle", "error");
            isContinuRecording = false;
        } finally {
            toggleButton.disabled = false;
            updateButtonState();
        }
    }

    async function startPushToTalkRecording() {
        if (!drawerGroqKey.value.trim() || !drawerOpenaiKey.value.trim()) {
            alert('Veuillez configurer vos cl√©s API dans le panneau de contr√¥le.');
            return;
        }
        if (!('MediaRecorder' in window) || (MediaRecorder.isTypeSupported && !MediaRecorder.isTypeSupported('audio/webm'))) {
            log("MediaRecorder non support√©", 'warning');
            alert("Push-to-Talk n'est pas support√© sur ce navigateur. Utilisez le mode Continu.");
            return;
        }

        updateStatus("Parlez maintenant...", "mic", "speaking");
        isPushToTalkRecording = true;
        updateButtonState();
        log("üé§ Push-to-Talk d√©marr√©", 'info');

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            recordedChunks = [];
            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
            mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
            mediaRecorder.onstop = async () => {
                const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                const arrayBuffer = await blob.arrayBuffer();
                const wavBuffer = await convertWebmToWavBuffer(arrayBuffer);
                await transcribeAudioUltraFast(wavBuffer);
            };
            mediaRecorder.start();
        } catch (error) {
            log(`Erreur Push-to-Talk: ${error.message}`, 'error');
            isPushToTalkRecording = false;
            updateButtonState();
        }
    }

    async function stopPushToTalkRecording() {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
        isPushToTalkRecording = false;
        updateButtonState();
        updateStatus("Traitement...", "loader-circle", "processing");
    }

    async function stopAllRecording() {
        if (myVad) { myVad.destroy(); myVad = null; }
        await cleanupPipeline();
        reflectionAudios.forEach(URL.revokeObjectURL);
        reflectionAudios.clear();
        isPlayingReflection = false;
        isContinuRecording = false;
        isPushToTalkRecording = false;
        updateButtonState();
        updateStatus("Pr√™t", "power-off", "");
        log("üõë Enregistrement arr√™t√©", 'info');
    }

    function switchToMode(mode) {
        if (isContinuRecording || isPushToTalkRecording) stopAllRecording();
        recordingMode = mode;
        updateModeButtons();
        updateButtonState();
        log(`Mode chang√© vers : ${mode}`, 'info');
    }

    function analyzeAudioQuality(audioData) {
        const energy = audioData.reduce((s, x) => s + x * x, 0) / audioData.length;
        if (energy < 0.0008) { log('Audio trop silencieux', 'warning'); return false; }
        return true;
    }

    function encodeWAV(samples, sampleRate = 16000) {
        const buffer = new ArrayBuffer(44 + samples.length * 2);
        const view = new DataView(buffer);
        const writeString = (o, s) => { for (let i = 0; i < s.length; i++) view.setUint8(o + i, s.charCodeAt(i)); };
        writeString(0, 'RIFF'); view.setUint32(4, 36 + samples.length * 2, true); writeString(8, 'WAVE'); writeString(12, 'fmt ');
        view.setUint32(16, 16, true); view.setUint16(20, 1, true); view.setUint16(22, 1, true); view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true); view.setUint16(32, 2, true); view.setUint16(34, 16, true); writeString(36, 'data');
        view.setUint32(40, samples.length * 2, true);
        for (let i = 0; i < samples.length; i++) {
            view.setInt16(44 + i * 2, Math.max(-1, Math.min(1, samples[i])) * 0x7FFF, true);
        }
        return buffer;
    }

    async function convertWebmToWavBuffer(webmBuffer) {
        const AudioCtx = window.AudioContext || window.webkitAudioContext;
        const audioCtx = new AudioCtx();
        const audioBuffer = await audioCtx.decodeAudioData(webmBuffer.slice(0));
        const samples = audioBuffer.getChannelData(0);
        return encodeWAV(samples, audioBuffer.sampleRate);
    }

    async function preGenerateSimpleReflections() {
        if (reflectionAudios.size > 0) return;
        log('üó£Ô∏è Pr√©-g√©n√©ration des r√©flexions...', 'info');
        const promises = SIMPLE_REFLECTIONS.map(async (phrase) => {
            try {
                const audioUrl = await generateTTSForSentence(phrase, drawerVoiceSelect.value, { cache: false });
                reflectionAudios.set(phrase, audioUrl);
            } catch (error) { /* ignore */ }
        });
        await Promise.all(promises);
        log(`üéâ ${reflectionAudios.size} r√©flexions pr√™tes !`, 'success');
    }

    function playRandomReflection() {
        if (isPlayingReflection || reflectionAudios.size === 0) return;
        const randomReflection = SIMPLE_REFLECTIONS[Math.floor(Math.random() * SIMPLE_REFLECTIONS.length)];
        const audioUrl = reflectionAudios.get(randomReflection);
        if (audioUrl) {
            isPlayingReflection = true;
            lastPlayedReflection = randomReflection;
            const reflectionAudio = new Audio(audioUrl);
            reflectionAudio.playsinline = true;
            reflectionAudio.play().catch(e => log('Erreur lecture r√©flexion', 'error'));
            reflectionAudio.onended = () => { isPlayingReflection = false; };
        }
    }

    function splitIntoSentences(text) {
        return text.match(/[^.!?]+[.!?]*|[^.!?]+$/g)?.map(s => s.trim()).filter(s => s.length > 3) || [];
    }

    async function generateTTSForSentence(sentence, voice, { cache = true } = {}) {
        const cacheKey = `${voice}_${sentence}`;
        if (cache && ttsCache.has(cacheKey)) return ttsCache.get(cacheKey);
        try {
            const response = await fetch("https://chatbot-20102024-8c94bbb4eddf.herokuapp.com/synthesize", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ text: sentence, voice }),
            });
            if (!response.ok) throw new Error(`HTTP ${response.status}`);
            const audioBlob = await response.blob();
            const audioUrl = URL.createObjectURL(audioBlob);
            if (cache) {
                if (ttsCache.size >= MAX_CACHE_SIZE) {
                    const [firstKey, firstUrl] = ttsCache.entries().next().value;
                    URL.revokeObjectURL(firstUrl);
                    ttsCache.delete(firstKey);
                }
                ttsCache.set(cacheKey, audioUrl);
            }
            return audioUrl;
        } catch (error) {
            log(`‚ùå Erreur TTS: ${error.message}`, 'error'); throw error;
        }
    }

    async function playAudioPipeline(sentences, voice) {
        for (let i = 0; i < sentences.length && pipelineActive; i++) {
            while (!readyAudioBuffer.has(i) && pipelineActive) await new Promise(r => setTimeout(r, 50));
            if (!pipelineActive) break;
            const audioData = readyAudioBuffer.get(i);
            readyAudioBuffer.delete(i);
            updateStatus(`IA parle... (${i + 1}/${sentences.length})`, "volume-2", "tts-playing");
            const audioElement = new Audio();
            audioElement.preload = 'auto';
            audioElement.playsinline = true;
            audioElement.src = audioData.audioUrl;
            await new Promise((resolve) => {
                audioElement.oncanplaythrough = async () => { try { await audioElement.play(); } catch {} };
                audioElement.onended = () => { audioElement.src=''; resolve(); };
                audioElement.onerror = () => resolve();
                setTimeout(() => { if (!audioElement.ended) { audioElement.pause(); resolve(); } }, 30000);
                if (!pipelineActive) resolve();
            });
        }
    }

    async function speakTextWithPipeline(text) {
        if (isProcessingTTS) return;
        if (/iPad|iPhone|iPod/.test(navigator.userAgent)) await initializeAudioContextForIOS();
        isProcessingTTS = isPlaying = pipelineActive = true;
        updateButtonState();
        const sentences = splitIntoSentences(text);
        if (sentences.length === 0) { await cleanupPipeline(); return; }
        log(`üöÄ D√©marrage pipeline TTS pour ${sentences.length} phrases`, 'info');
        readyAudioBuffer.clear();
        generationWorkers = [];
        try {
            const worker = (async () => {
                for (let i = 0; i < sentences.length && pipelineActive; i++) {
                    if (readyAudioBuffer.size >= MAX_BUFFER_SIZE) { await new Promise(r => setTimeout(r, 100)); i--; continue; }
                    try {
                        const audioUrl = await generateTTSForSentence(sentences[i], drawerVoiceSelect.value);
                        if (pipelineActive) readyAudioBuffer.set(i, { audioUrl, sentence: sentences[i] });
                    } catch {}
                }
            })();
            generationWorkers.push(worker);
            await playAudioPipeline(sentences, drawerVoiceSelect.value);
        } catch (error) {
            log(`Erreur pipeline: ${error.message}`, 'error');
        } finally {
            await cleanupPipeline();
        }
    }

    async function cleanupPipeline() {
        pipelineActive = false;
        isProcessingTTS = false;
        isPlaying = false;
        readyAudioBuffer.clear();
        await Promise.allSettled(generationWorkers);
        generationWorkers = [];
        if (ttsAudio) { ttsAudio.pause(); ttsAudio.src = ""; }
        updateButtonState();
        if (isContinuRecording) updateStatus("En √©coute...", "mic", "listening");
        else if (!isPushToTalkRecording) updateStatus("Pr√™t", "power-off", "");
    }

    function interruptTTS() {
        if ((isPlaying || isProcessingTTS) && drawerAllowInterrupt.checked) {
            log('üõë TTS Interrompu !', 'warning');
            cleanupPipeline();
            updateStatus("Interruption !", "zap-off", "interrupted");
            showInterruptIndicator();
            addToConversation('system', 'R√©ponse interrompue');
            setTimeout(() => { if(isContinuRecording) updateStatus("En √©coute...", "mic", "listening"); }, 800);
            return true;
        }
        return false;
    }

    function showInterruptIndicator() {
        interruptIndicator?.classList.add('opacity-100');
        setTimeout(() => interruptIndicator?.classList.remove('opacity-100'), 1500);
    }

    async function transcribeAudioUltraFast(audioData) {
        if (recordingMode !== 'push-to-talk' && audioData instanceof Float32Array && !analyzeAudioQuality(audioData)) {
            updateStatus("En √©coute...", "mic", "listening"); return;
        }
        updateStatus("Transcription...", "loader-circle", "processing");
        try {
            const wavBuffer = audioData instanceof ArrayBuffer ? audioData : encodeWAV(audioData);
            const formData = new FormData();
            formData.append('file', new Blob([wavBuffer], { type: 'audio/wav' }), 'audio.wav');
            formData.append('model', 'whisper-large-v3');
            formData.append('language', 'fr');
            const response = await fetch('https://api.groq.com/openai/v1/audio/transcriptions', {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${drawerGroqKey.value}` },
                body: formData
            });
            if (!response.ok) throw new Error(`Transcription √©chou√©e: ${response.statusText}`);
            const result = await response.json();
            const userText = result.text?.trim();
            const parasiteFilters = [/sous-titrage/i, /radio-canada/i, /src subtitle/i];
            if (!userText || parasiteFilters.some(f => f.test(userText))) {
                log('Transcription vide ou parasite ignor√©e.', 'warning');
                if (isContinuRecording) updateStatus("En √©coute...", "mic", "listening");
                else updateStatus("Pr√™t", "power-off", "");
                return;
            }
            await processUserMessage(userText);
        } catch (error) {
            log(`Erreur transcription: ${error.message}`, 'error');
            if (isContinuRecording) updateStatus("En √©coute...", "mic", "listening");
            else updateStatus("Pr√™t", "power-off", "");
        }
    }

    async function processUserMessage(userText) {
        if (!userText) return;
        addToConversation('user', userText);
        const aiResponse = await getLLMResponse(userText);
        if (aiResponse) {
            addToConversation('assistant', aiResponse);
            if (drawerAutoSpeak.checked) speakTextWithPipeline(aiResponse);
        }
        if (isContinuRecording && !isProcessingTTS) updateStatus("En √©coute...", "mic", "listening");
        else if (!isContinuRecording && !isPushToTalkRecording) updateStatus("Pr√™t", "power-off", "");
    }

    async function getLLMResponse(userMessage) {
        log('üöÄ Requ√™te OpenAI GPT-4o Mini...', 'info');
        updateStatus("IA r√©fl√©chit...", "brain-circuit", "processing");
        try {
            const supportsStreaming = !!(window.ReadableStream && window.fetch);
            const messages = [
                { role: "system", content: "Tu es un assistant vocal conversationnel naturel. R√©ponds en fran√ßais parl√©, sans √©motic√¥nes, ast√©risques ou formatage. Sois concis (2-3 phrases max)." },
                ...conversationHistory.slice(-10),
                { role: 'user', content: userMessage }
            ];
            if (lastPlayedReflection) {
                messages.push({ role: "system", content: `INFO CONTEXTE: Tu viens de dire "${lastPlayedReflection}". Ne le r√©p√®te pas.` });
            }
            if (supportsStreaming) {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: { 'Authorization': `Bearer ${drawerOpenaiKey.value}`, 'Content-Type': 'application/json' },
                    body: JSON.stringify({ model: 'gpt-4o-mini', messages, temperature: 0.5, max_tokens: 150, stream: true })
                });
                if (!response.ok) {
                    const err = await response.json();
                    throw new Error(err.error?.message || 'Erreur API OpenAI');
                }
                let fullResponse = '';
                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    const chunk = decoder.decode(value);
                    const lines = chunk.split('\n');
                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const data = line.slice(6);
                            if (data === '[DONE]') { try { reader.cancel(); } catch {} break; }
                            try {
                                const parsed = JSON.parse(data);
                                fullResponse += parsed.choices[0]?.delta?.content || '';
                            } catch {}
                        }
                    }
                }
                lastPlayedReflection = "";
                log('‚úÖ R√©ponse OpenAI re√ßue', 'success');
                return fullResponse.trim();
            } else {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: { 'Authorization': `Bearer ${drawerOpenaiKey.value}`, 'Content-Type': 'application/json' },
                    body: JSON.stringify({ model: 'gpt-4o-mini', messages, temperature: 0.5, max_tokens: 150, stream: false })
                });
                if (!response.ok) throw new Error('Erreur OpenAI');
                const data = await response.json();
                const txt = data.choices?.[0]?.message?.content?.trim() || '';
                lastPlayedReflection = "";
                return txt;
            }
        } catch (error) {
            log(`Erreur OpenAI: ${error.message}`, 'error');
            lastPlayedReflection = "";
            return `D√©sol√©, une erreur est survenue avec l'IA: ${error.message}`;
        }
    }

    function addToConversation(type, content) {
        if (!conversationHistoryEl || !content) return;
        if (conversationHistoryEl.querySelector('.italic')) conversationHistoryEl.innerHTML = '';
        conversationHistory.push({ role: type, content });
        if (conversationHistory.length > 30) conversationHistory.shift();

        const wrapper = document.createElement('div');
        const baseClasses = 'mb-3 px-4 py-3 rounded-2xl max-w-[85%] break-words shadow-md';

        if (type === 'system') {
            wrapper.className = `${baseClasses} text-center text-xs text-white/50 italic w-full`;
            wrapper.textContent = `--- ${content} ---`;
        } else {
            const isUser = type === 'user';
            wrapper.className = `${baseClasses} ${isUser ? 'bg-blue-500 text-white ml-auto rounded-br-md' : 'bg-white/90 text-gray-800 mr-auto rounded-bl-md'}`;
            const header = document.createElement('div');
            header.className = isUser ? 'text-xs opacity-80 mb-1' : 'text-xs text-gray-600 opacity-70 mb-1 flex justify-between items-center';
            if (isUser) {
                header.textContent = 'Vous';
            } else {
                const left = document.createElement('span'); left.textContent = 'Assistant';
                const btn = document.createElement('button'); btn.textContent = 'üîä'; btn.className = 'text-gray-600 hover:text-black transition-transform'; btn.onclick = () => speakTextWithPipeline(content);
                header.appendChild(left); header.appendChild(btn);
            }
            const body = document.createElement('div'); body.textContent = content;
            wrapper.appendChild(header); wrapper.appendChild(body);
        }
        conversationHistoryEl.appendChild(wrapper);
        conversationHistoryEl.scrollTop = conversationHistoryEl.scrollHeight;
    }

    window.onload = () => {
        voiceCircle = document.getElementById('voice-circle');
        statusText = document.getElementById('status-text');
        toggleButton = document.getElementById('toggleButton');
        toggleIconEl = document.getElementById('toggleIconEl');
        toggleText = document.getElementById('toggleText');
        ttsAudio = document.getElementById('ttsAudio');
        interruptIndicator = document.getElementById('interrupt-indicator');
        processingIndicator = document.getElementById('processing-indicator');
        textInput = document.getElementById('text-input');
        sendButton = document.getElementById('send-button');
        modeButtons = document.getElementById('modeButtons');
        modeContinu = document.getElementById('modeContinu');
        modePushToTalk = document.getElementById('modePushToTalk');
        conversationDrawer = document.getElementById('conversationDrawer');
        conversationHistoryEl = document.getElementById('conversationHistory');
        settingsDrawer = document.getElementById('settingsDrawer');
        drawerOverlay = document.getElementById('drawerOverlay');
        drawerGroqKey = document.getElementById('drawerGroqKey');
        drawerOpenaiKey = document.getElementById('drawerOpenaiKey');
        drawerAutoSpeak = document.getElementById('drawerAutoSpeak');
        drawerAllowInterrupt = document.getElementById('drawerAllowInterrupt');
        drawerVoiceSelect = document.getElementById('drawerVoiceSelect');
        drawerDebug = document.getElementById('drawerDebug');
        legacyControls = document.getElementById('legacyControls');
        legacyAudioInput = document.getElementById('legacyAudioInput');
        legacyRecordBtn = document.getElementById('legacyRecordBtn');

        updateStatus("Pr√™t", "power-off", "");
        updateButtonState();
        updateModeButtons();

        drawerGroqKey.value = localStorage.getItem('groq_api_key') || '';
        drawerOpenaiKey.value = localStorage.getItem('openai_api_key') || '';
        drawerAutoSpeak.checked = localStorage.getItem('auto_speak') !== 'false';
        drawerAllowInterrupt.checked = localStorage.getItem('allow_interrupt') !== 'false';
        drawerVoiceSelect.value = localStorage.getItem('selected_voice') || 'fr-FR-DeniseNeural';

        toggleButton.onclick = () => { if (recordingMode === 'continu') toggleMasterRecording(); else togglePushToTalk(); };
        modeContinu.onclick = () => switchToMode('continu');
        modePushToTalk.onclick = () => switchToMode('push-to-talk');

        sendButton.onclick = () => {
            const msg = textInput.value.trim();
            if (!msg) return;
            processUserMessage(msg);
            textInput.value = '';
        };
        textInput.onkeydown = (e) => {
            if (e.key === 'Enter') {
                e.preventDefault();
                const msg = textInput.value.trim();
                if (!msg) return;
                processUserMessage(msg);
                textInput.value = '';
            }
        };

        document.getElementById('conversationToggle').onclick = () => { conversationDrawer.classList.remove('-translate-x-full'); drawerOverlay.classList.remove('opacity-0', 'pointer-events-none'); };
        document.getElementById('drawerToggle').onclick = () => { settingsDrawer.classList.remove('translate-x-full'); drawerOverlay.classList.remove('opacity-0', 'pointer-events-none'); };
        const closeDrawers = () => { conversationDrawer.classList.add('-translate-x-full'); settingsDrawer.classList.add('translate-x-full'); drawerOverlay.classList.add('opacity-0', 'pointer-events-none'); };
        document.getElementById('conversationDrawerClose').onclick = closeDrawers;
        document.getElementById('settingsDrawerClose').onclick = closeDrawers;
        drawerOverlay.onclick = closeDrawers;
        document.onkeydown = (e) => { if (e.key === 'Escape') closeDrawers(); };

        drawerGroqKey.oninput = () => localStorage.setItem('groq_api_key', drawerGroqKey.value);
        drawerOpenaiKey.oninput = () => localStorage.setItem('openai_api_key', drawerOpenaiKey.value);
        drawerAutoSpeak.onchange = () => localStorage.setItem('auto_speak', drawerAutoSpeak.checked);
        drawerAllowInterrupt.onchange = () => localStorage.setItem('allow_interrupt', drawerAllowInterrupt.checked);
        drawerVoiceSelect.onchange = () => localStorage.setItem('selected_voice', drawerVoiceSelect.value);

        document.getElementById('drawerClearCache').onclick = () => { transcriptionCache.clear(); ttsCache.clear(); log('Cache vid√©', 'success'); };
        document.getElementById('drawerExportConversation').onclick = () => {
            const data = JSON.stringify(conversationHistory, null, 2);
            const a = document.createElement('a');
            a.href = URL.createObjectURL(new Blob([data], { type: 'application/json' }));
            a.download = `conversation_${new Date().toISOString().slice(0,10)}.json`;
            a.click();
            URL.revokeObjectURL(a.href);
            log('Conversation export√©e', 'success');
        };

        const updateTime = () => { document.getElementById('time').textContent = new Date().toLocaleTimeString('fr-FR', { hour: '2-digit', minute: '2-digit' }); };
        updateTime();
        setInterval(updateTime, 10000);

        lucide.createIcons();
        log('üéØ Syst√®me initialis√© avec succ√®s!', 'success');

        const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
        if (isIOS) {
            document.addEventListener('touchstart', async function initAudioOnFirstTouch() {
                await initializeAudioContextForIOS();
                document.removeEventListener('touchstart', initAudioOnFirstTouch);
            }, { once: true });
        }

        // Mode legacy si pas de modules -> g√©r√© par <script nomodule> ci-dessous.
        // Ici, on affiche les contr√¥les normaux.
        legacyControls.classList.add('hidden');
        toggleButton.style.display = '';
        modeButtons.style.display = '';
        window.onbeforeunload = stopAllRecording;
    };
    </script>

    <!-- Script LEGACY (sans modules) pour anciens Safari (iPad 2, etc.) -->
    <script nomodule>
    (function(){
        var voiceCircle = document.getElementById('voice-circle');
        var statusText = document.getElementById('status-text');
        var toggleButton = document.getElementById('toggleButton');
        var modeButtons = document.getElementById('modeButtons');
        var conversationHistoryEl = document.getElementById('conversationHistory');
        var sendButton = document.getElementById('send-button');
        var textInput = document.getElementById('text-input');
        var legacyControls = document.getElementById('legacyControls');
        var legacyAudioInput = document.getElementById('legacyAudioInput');
        var legacyRecordBtn = document.getElementById('legacyRecordBtn');
        var drawerGroqKey = document.getElementById('drawerGroqKey');
        var drawerOpenaiKey = document.getElementById('drawerOpenaiKey');
        var drawerVoiceSelect = document.getElementById('drawerVoiceSelect');
        var drawerAutoSpeak = document.getElementById('drawerAutoSpeak');

        function updateStatus(text, iconName, stateClass) {
            if (statusText) statusText.textContent = text;
            if (voiceCircle) {
                voiceCircle.innerHTML = '<i data-lucide="'+iconName+'" class="w-16 h-16"></i>';
                voiceCircle.className = "w-[200px] h-[200px] rounded-full mx-auto mb-2.5 flex items-center justify-center text-6xl transition-all duration-300 bg-white/10 backdrop-blur-xl border-2 border-white/20";
            }
            if (window.lucide) window.lucide.createIcons();
        }

        function addBubble(type, content) {
            if (!conversationHistoryEl || !content) return;
            if (conversationHistoryEl.querySelector('.italic')) conversationHistoryEl.innerHTML = '';
            var wrapper = document.createElement('div');
            var base = 'mb-3 px-4 py-3 rounded-2xl max-w-[85%] break-words shadow-md';
            if (type === 'system') {
                wrapper.className = base + ' text-center text-xs text-white/50 italic w-full';
                wrapper.textContent = '--- ' + content + ' ---';
            } else {
                var isUser = type === 'user';
                wrapper.className = base + (isUser ? ' bg-blue-500 text-white ml-auto rounded-br-md' : ' bg-white/90 text-gray-800 mr-auto rounded-bl-md');
                var header = document.createElement('div');
                header.className = isUser ? 'text-xs opacity-80 mb-1' : 'text-xs text-gray-600 opacity-70 mb-1';
                header.textContent = isUser ? 'Vous' : 'Assistant';
                var body = document.createElement('div');
                body.textContent = content;
                wrapper.appendChild(header);
                wrapper.appendChild(body);
            }
            conversationHistoryEl.appendChild(wrapper);
            conversationHistoryEl.scrollTop = conversationHistoryEl.scrollHeight;
        }

        function xhrJSON(url, method, headers, body, onOk, onErr) {
            try {
                var xhr = new XMLHttpRequest();
                xhr.open(method || 'GET', url, true);
                if (headers) for (var k in headers) if (headers.hasOwnProperty(k)) xhr.setRequestHeader(k, headers[k]);
                xhr.onreadystatechange = function(){
                    if (xhr.readyState === 4) {
                        if (xhr.status >= 200 && xhr.status < 300) {
                            try { onOk(JSON.parse(xhr.responseText)); } catch(e){ onErr(e); }
                        } else { onErr(new Error('HTTP ' + xhr.status)); }
                    }
                };
                xhr.send(body || null);
            } catch (e) { onErr(e); }
        }

        function xhrBlob(url, method, headers, body, onOk, onErr) {
            try {
                var xhr = new XMLHttpRequest();
                xhr.open(method || 'GET', url, true);
                if (headers) for (var k in headers) if (headers.hasOwnProperty(k)) xhr.setRequestHeader(k, headers[k]);
                xhr.responseType = 'arraybuffer';
                xhr.onload = function(){
                    if (xhr.status >= 200 && xhr.status < 300) {
                        try { onOk(new Blob([xhr.response])); } catch(e){ onErr(e); }
                    } else { onErr(new Error('HTTP ' + xhr.status)); }
                };
                xhr.onerror = function(){ onErr(new Error('Network error')); };
                xhr.send(body || null);
            } catch (e) { onErr(e); }
        }

        function playTTS(text) {
            var voice = drawerVoiceSelect.value || 'fr-FR-DeniseNeural';
            var payload = JSON.stringify({ text: text, voice: voice });
            xhrBlob('https://chatbot-20102024-8c94bbb4eddf.herokuapp.com/synthesize', 'POST', { 'Content-Type': 'application/json' }, payload, function(blob){
                try {
                    var url = URL.createObjectURL(blob);
                    var a = new Audio();
                    a.src = url;
                    a.play();
                    a.onended = function(){ URL.revokeObjectURL(url); };
                } catch(e){}
            }, function(err){
                console.log('TTS err', err);
            });
        }

        function legacyTranscribeAndReply(file) {
            if (!file) return;
            if (!drawerGroqKey.value || !drawerOpenaiKey.value) {
                alert('Renseignez vos cl√©s API dans le panneau de contr√¥le.');
                return;
            }
            updateStatus('Transcription...', 'loader-circle', 'processing');

            var form = new FormData();
            form.append('file', file, file.name || 'audio.m4a');
            form.append('model', 'whisper-large-v3');
            form.append('language', 'fr');

            xhrJSON('https://api.groq.com/openai/v1/audio/transcriptions', 'POST',
                { 'Authorization': 'Bearer ' + drawerGroqKey.value },
                form,
                function(res){
                    var userText = (res && res.text || '').trim();
                    if (!userText) { updateStatus('Pr√™t', 'power-off', ''); return; }
                    addBubble('user', userText);
                    updateStatus('IA r√©fl√©chit...', 'brain-circuit', 'processing');

                    var messages = [
                        { role: "system", content: "Tu es un assistant vocal conversationnel naturel. R√©ponds en fran√ßais parl√©, sans √©motic√¥nes, ast√©risques ou formatage. Sois concis (2-3 phrases max)." },
                        { role: "user", content: userText }
                    ];
                    var body = JSON.stringify({ model: 'gpt-4o-mini', messages: messages, temperature: 0.5, max_tokens: 150, stream: false });

                    xhrJSON('https://api.openai.com/v1/chat/completions', 'POST',
                        { 'Authorization': 'Bearer ' + drawerOpenaiKey.value, 'Content-Type': 'application/json' },
                        body,
                        function(data){
                            try {
                                var answer = (data.choices && data.choices[0] && data.choices[0].message && data.choices[0].message.content) || '';
                                answer = (answer || '').trim();
                                if (answer) {
                                    addBubble('assistant', answer);
                                    updateStatus('Pr√™t', 'power-off', '');
                                    if (drawerAutoSpeak && drawerAutoSpeak.checked) playTTS(answer);
                                } else {
                                    updateStatus('Pr√™t', 'power-off', '');
                                }
                            } catch(e){
                                updateStatus('Pr√™t', 'power-off', '');
                            }
                        },
                        function(err){
                            console.log('OpenAI err', err);
                            addBubble('assistant', "D√©sol√©, une erreur est survenue avec l'IA.");
                            updateStatus('Pr√™t', 'power-off', '');
                        }
                    );
                },
                function(err){
                    console.log('Groq err', err);
                    updateStatus('Pr√™t', 'power-off', '');
                }
            );
        }

        // Activer le mode Legacy UI
        toggleButton.style.display = 'none';
        modeButtons.style.display = 'none';
        legacyControls.classList.remove('hidden');
        updateStatus('Mode iOS ancien pr√™t', 'power-off', '');

        document.getElementById('conversationToggle').onclick = function(){
            var drawer = document.getElementById('conversationDrawer');
            var overlay = document.getElementById('drawerOverlay');
            drawer.classList.remove('-translate-x-full');
            overlay.classList.remove('opacity-0', 'pointer-events-none');
        };
        document.getElementById('drawerToggle').onclick = function(){
            var drawer = document.getElementById('settingsDrawer');
            var overlay = document.getElementById('drawerOverlay');
            drawer.classList.remove('translate-x-full');
            overlay.classList.remove('opacity-0', 'pointer-events-none');
        };
        var closeDrawers = function(){
            document.getElementById('conversationDrawer').classList.add('-translate-x-full');
            document.getElementById('settingsDrawer').classList.add('translate-x-full');
            document.getElementById('drawerOverlay').classList.add('opacity-0', 'pointer-events-none');
        };
        document.getElementById('conversationDrawerClose').onclick = closeDrawers;
        document.getElementById('settingsDrawerClose').onclick = closeDrawers;
        document.getElementById('drawerOverlay').onclick = closeDrawers;

        // Bouton legacy pour enregistrer/choisir un fichier audio
        legacyRecordBtn.onclick = function(){
            legacyAudioInput.click();
        };
        legacyAudioInput.onchange = function(e){
            var file = (e.target && e.target.files && e.target.files[0]) || null;
            if (!file) return;
            legacyTranscribeAndReply(file);
            // reset input (permet d‚Äôenregistrer deux fois de suite)
            e.target.value = '';
        };

        // Envoi texte (fallback)
        sendButton.onclick = function(){
            var msg = textInput.value ? textInput.value.trim() : '';
            if (!msg) return;
            addBubble('user', msg);
            textInput.value = '';
            if (!drawerOpenaiKey.value) { addBubble('assistant', "Renseignez la cl√© OpenAI."); return; }
            updateStatus('IA r√©fl√©chit...', 'brain-circuit', 'processing');
            var messages = [
                { role: "system", content: "Tu es un assistant vocal conversationnel naturel. R√©ponds en fran√ßais parl√©, sans √©motic√¥nes, ast√©risques ou formatage. Sois concis (2-3 phrases max)." },
                { role: "user", content: msg }
            ];
            var body = JSON.stringify({ model: 'gpt-4o-mini', messages: messages, temperature: 0.5, max_tokens: 150, stream: false });
            xhrJSON('https://api.openai.com/v1/chat/completions', 'POST',
                { 'Authorization': 'Bearer ' + drawerOpenaiKey.value, 'Content-Type': 'application/json' },
                body,
                function(data){
                    try {
                        var answer = (data.choices && data.choices[0] && data.choices[0].message && data.choices[0].message.content) || '';
                        answer = (answer || '').trim();
                        if (answer) {
                            addBubble('assistant', answer);
                            if (drawerAutoSpeak && drawerAutoSpeak.checked) playTTS(answer);
                        }
                        updateStatus('Pr√™t', 'power-off', '');
                    } catch(e){
                        updateStatus('Pr√™t', 'power-off', '');
                    }
                },
                function(err){
                    addBubble('assistant', "Erreur OpenAI.");
                    updateStatus('Pr√™t', 'power-off', '');
                }
            );
        };
    })();
    </script>

    <script>
        // Horloge visible en legacy et moderne
        function updateTime() {
            var el = document.getElementById('time');
            if (el) el.textContent = new Date().toLocaleTimeString('fr-FR', { hour: '2-digit', minute: '2-digit' });
        }
        updateTime();
        setInterval(updateTime, 10000);
    </script>
</body>
</html>