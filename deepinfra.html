<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ultra-Fast iPhone Style Voice Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://unpkg.com/lucide@latest/dist/umd/lucide.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    fontFamily: {
                        sans: ['Inter', '-apple-system', 'BlinkMacSystemFont', 'Segoe UI', 'Roboto', 'sans-serif'],
                    },
                    borderRadius: { '4xl': '2rem', '5xl': '2.5rem' },
                    keyframes: {
                        pulse: {
                            '0%, 100%': { boxShadow: '0 0 0 0 rgba(74, 222, 128, 0.7)' },
                            '70%': { boxShadow: '0 0 0 10px rgba(74, 222, 128, 0)' },
                        },
                        'tts-pulse': {
                            '0%, 100%': { boxShadow: '0 0 0 0 rgba(168, 85, 247, 0.7)' },
                            '70%': { boxShadow: '0 0 0 10px rgba(168, 85, 247, 0)' },
                        },
                        'interrupt-flash': {
                            '0%': { boxShadow: '0 0 0 0 rgba(239, 68, 68, 0.8)' },
                            '50%': { boxShadow: '0 0 0 15px rgba(239, 68, 68, 0.4)' },
                            '100%': { boxShadow: '0 0 0 0 rgba(239, 68, 68, 0)' },
                        },
                        'processing-spin': {
                            '0%': { transform: 'rotate(0deg)' },
                            '100%': { transform: 'rotate(360deg)' },
                        },
                    },
                    animation: {
                        pulse: 'pulse 2s infinite',
                        'tts-pulse': 'tts-pulse 1.5s infinite',
                        'interrupt-flash': 'interrupt-flash 0.5s ease-out',
                        'processing-spin': 'processing-spin 1s linear infinite',
                    },
                },
            },
        }
    </script>
    <style>
        ::-webkit-scrollbar { width: 4px; }
        ::-webkit-scrollbar-track { background: rgba(255,255,255,0.1); border-radius: 10px; }
        ::-webkit-scrollbar-thumb { background: rgba(255,255,255,0.3); border-radius: 10px; }
        
        #toggleButton {
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            transform-origin: center;
        }
        #toggleButton:active { transform: scale(0.95); }
        #toggleButton:disabled { transform: scale(1); opacity: 0.5; }
    </style>
</head>
<body class="bg-gradient-to-br from-[#1e3a8a] to-[#3730a3] min-h-screen flex items-center justify-center font-sans text-white overflow-hidden">

    <div class="w-full h-full bg-gradient-to-br from-[#1e3c72]/80 to-[#2a5298]/80 relative flex flex-col">

        <div class="fixed top-0 left-0 w-full z-20">
            <div class="flex justify-between items-center px-5 py-3 text-white text-sm font-semibold">
                <button id="conversationToggle" class="p-2 rounded-lg bg-white/10 hover:bg-white/20 transition-colors">
                     <i data-lucide="message-square-text" class="w-5 h-5"></i>
                </button>
                <div id="time" class="font-bold">9:41</div>
                <button id="drawerToggle" class="p-2 rounded-lg bg-white/10 hover:bg-white/20 transition-colors">
                    <i data-lucide="sliders-horizontal" class="w-5 h-5"></i>
                </button>
            </div>
        </div>
        
        <div class="flex-1 flex flex-col justify-center items-center px-5 pt-16 pb-48">
            <div class="relative flex-shrink-0 text-center">
                <div id="voice-circle" class="w-[200px] h-[200px] rounded-full mx-auto mb-2.5 flex items-center justify-center text-6xl transition-all duration-300 bg-white/10 backdrop-blur-xl border-2 border-white/20">
                    <i data-lucide="power-off" class="w-16 h-16"></i>
                </div>
                <div id="status-text" class="text-center text-white text-lg font-medium">Ready to start</div>
                <div id="interrupt-indicator" class="absolute -bottom-8 left-1/2 -translate-x-1/2 bg-red-500/80 text-white px-4 py-2 rounded-full text-xs opacity-0 transition-opacity duration-300">Interrupted!</div>
                <div id="processing-indicator" class="absolute -bottom-16 left-1/2 -translate-x-1/2 bg-blue-500/80 text-white px-4 py-2 rounded-full text-xs opacity-0 transition-opacity duration-300">‚ö° Processing...</div>
            </div>
        </div>

        <div class="fixed bottom-0 left-0 w-full z-20 p-4 bg-gradient-to-t from-[#1e3a8a] to-transparent">
             <div class="max-w-md mx-auto space-y-3">
                <button id="toggleButton" class="w-full py-4 rounded-2xl font-semibold text-base transition-all backdrop-blur-xl bg-green-500/80 text-white disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2">
                    <i data-lucide="mic" id="toggleIconEl"></i>
                    <span id="toggleText">Start</span>
                </button>
                
                <div class="flex justify-center items-center gap-2">
                    <button id="modeContinu" class="flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-green-500/80 text-white">
                        üîÑ Continuous
                    </button>
                    <button id="modePushToTalk" class="flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-white/20 text-white/70 hover:bg-white/30">
                        üé§ Push-to-Talk
                    </button>
                </div>
                
                <div class="flex gap-2">
                    <input type="text" id="text-input" placeholder="Send a message..." class="flex-1 bg-white/10 border border-white/20 rounded-xl px-4 py-3 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15">
                    <button id="send-button" class="p-3 bg-green-500/80 rounded-xl text-white hover:bg-green-500/100 transition-colors">
                         <i data-lucide="send-horizontal" class="w-6 h-6"></i>
                    </button>
                </div>
            </div>
        </div>
    </div>

    <audio id="ttsAudio" style="display: none;" preload="auto"></audio>

    <div id="conversationDrawer" class="fixed inset-y-0 left-0 z-50 w-full sm:w-96 bg-gradient-to-b from-[#19356d] to-[#26488b] shadow-xl transform -translate-x-full transition-transform duration-300 ease-in-out flex flex-col">
        <div class="flex items-center justify-between p-4 border-b border-white/20 flex-shrink-0">
            <h2 class="text-white text-lg font-semibold">üí¨ Conversation</h2>
            <button id="conversationDrawerClose" class="text-white/70 hover:text-white transition-colors">
                 <i data-lucide="x" class="w-6 h-6"></i>
            </button>
        </div>
        <div id="conversationHistory" class="p-4 overflow-y-auto flex-1">
            <div class="text-white/60 text-center italic mt-10">
                Conversation history will appear here...
            </div>
        </div>
    </div>
    
    <div id="settingsDrawer" class="fixed inset-y-0 right-0 z-50 w-full sm:w-96 bg-gradient-to-b from-[#19356d] to-[#26488b] shadow-xl transform translate-x-full transition-transform duration-300 ease-in-out flex flex-col">
        <div class="flex items-center justify-between p-4 border-b border-white/20 flex-shrink-0">
            <h2 class="text-white text-lg font-semibold">‚öôÔ∏è Control Panel</h2>
            <button id="settingsDrawerClose" class="text-white/70 hover:text-white transition-colors">
                <i data-lucide="x" class="w-6 h-6"></i>
            </button>
        </div>
        <div class="p-4 space-y-4 overflow-y-auto flex-1">
            <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">üîß API Settings</h3>
                <input type="password" id="drawerGroqKey" placeholder="Groq API Key (STT)" class="w-full bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15 mb-3">
                <input type="password" id="drawerOpenaiKey" placeholder="OpenAI API Key (LLM)" class="w-full bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15 mb-3">
                <input type="password" id="drawerDeepinfraKey" placeholder="DeepInfra API Key (TTS)" class="w-full bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm placeholder-white/60 focus:outline-none focus:border-green-400/50 focus:bg-white/15 mb-3">
                
                <div class="grid grid-cols-2 gap-3 text-sm mt-3">
                    <label class="flex items-center gap-2 cursor-pointer"><input type="checkbox" id="drawerAutoSpeak" class="accent-green-400"> Auto TTS</label>
                    <label class="flex items-center gap-2 cursor-pointer"><input type="checkbox" id="drawerAllowInterrupt" class="accent-green-400"> Interruption</label>
                </div>
            </div>

            <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">üéõÔ∏è TTS Settings</h3>
                <select id="drawerVoiceSelect" class="w-full mb-3 bg-white/10 border border-white/20 rounded-lg px-3 py-2 text-white text-sm appearance-none">
                    <option value="default">Default Voice</option>
                     <option value="s9yqajxurexb7xb42pcq">Ma Voix Clon√©e</option> <!-- VOTRE LIGNE AJOUT√âE -->
                     <option value="ej94wlw9ggxnsgwkrc7s">Ma Voix Clon√©e</option> <!-- VOTRE LIGNE AJOUT√âE -->
                    <option value="custom_voice_1">Custom Voice 1</option>
                    <option value="custom_voice_2">Custom Voice 2</option>
                    <!-- Add other custom voice_ids here -->
                </select>
                <div class="space-y-3">
                    <div>
                        <label class="text-white text-sm flex justify-between"><span>Exaggeration</span><span id="ttsExaggerationValue" class="text-white/70">0.25</span></label>
                        <input type="range" id="ttsExaggeration" min="0" max="1" step="0.05" value="0.25" class="w-full accent-green-400">
                    </div>
                    <div>
                        <label class="text-white text-sm flex justify-between"><span>CFG</span><span id="ttsCfgValue" class="text-white/70">0.5</span></label>
                        <input type="range" id="ttsCfg" min="0.1" max="1" step="0.05" value="0.5" class="w-full accent-green-400">
                    </div>
                    <div>
                        <label class="text-white text-sm flex justify-between"><span>Temperature</span><span id="ttsTemperatureValue" class="text-white/70">0.7</span></label>
                        <input type="range" id="ttsTemperature" min="0" max="2" step="0.1" value="0.7" class="w-full accent-green-400">
                    </div>
                </div>
            </div>

             <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">‚ö° Actions</h3>
                <div class="space-y-2">
                    <button id="drawerClearCache" class="w-full flex items-center justify-center gap-2 py-2 bg-red-500/80 hover:bg-red-500 rounded-lg text-white text-sm transition-colors"><i data-lucide="trash-2" class="w-4 h-4"></i> Clear Cache</button>
                    <button id="drawerExportConversation" class="w-full flex items-center justify-center gap-2 py-2 bg-blue-500/80 hover:bg-blue-500 rounded-lg text-white text-sm transition-colors"><i data-lucide="download" class="w-4 h-4"></i> Export</button>
                </div>
            </div>
            <div class="bg-white/10 backdrop-blur-xl rounded-xl p-4 border border-white/20">
                <h3 class="text-white font-medium mb-3">üîç Debug Log</h3>
                <div id="drawerDebug" class="bg-black/20 rounded-lg p-3 text-xs text-white/70 h-48 overflow-y-auto">
                    <div>‚ö° System ready...</div>
                </div>
            </div>
        </div>
    </div>

    <div id="drawerOverlay" class="fixed inset-0 bg-black/50 z-40 opacity-0 pointer-events-none transition-opacity duration-300"></div>

    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
    
    <script>
    // =============================================
    // üöÄ ULTRA-FAST VOICE ASSISTANT
    // =============================================
    
    // üîß DOM & STATE VARIABLES
    let myVad = null;
    let conversationHistory = [];
    let isPlaying = false;
    let isProcessingTTS = false;
    let pipelineActive = false;
    let generationWorkers = [];
    let readyAudioBuffer = new Map();
    let lastPlayedReflection = "";
    let recordingMode = 'continu';
    let isPushToTalkRecording = false;
    let isContinuRecording = false;
    let pushToTalkAudio = [];
    let mediaRecorder, recordedChunks = [];
    const transcriptionCache = new Map();
    const ttsCache = new Map();
    const MAX_CACHE_SIZE = 50;
    const MAX_BUFFER_SIZE = 3;
    const baseCircleClasses = "w-[200px] h-[200px] rounded-full mx-auto mb-2.5 flex items-center justify-center text-6xl transition-all duration-300 backdrop-blur-xl";

    let toggleButton, toggleIconEl, toggleText, voiceCircle, statusText, ttsAudio, interruptIndicator, processingIndicator, textInput, sendButton;
    let modeContinu, modePushToTalk;
    let conversationDrawer, conversationHistoryEl, settingsDrawer, drawerOverlay;
    let drawerGroqKey, drawerOpenaiKey, drawerDeepinfraKey, drawerAutoSpeak, drawerAllowInterrupt, drawerVoiceSelect, drawerDebug;
    let ttsExaggeration, ttsCfg, ttsTemperature;
    let ttsExaggerationValue, ttsCfgValue, ttsTemperatureValue;
    
    // üí≠ SIMPLE REFLECTIONS (in English)
    const SIMPLE_REFLECTIONS = ["I see...", "Okay, got it...", "Hmm, interesting...", "Right...", "Let me see...", "Sure...", "Okay...", "Understood..."];
    let reflectionAudios = new Map();
    let isPlayingReflection = false;

    // =============================================
    // üîß UTILITY & UI FUNCTIONS
    // =============================================
    function getDeepInfraApiKey() {
        const storedKey = localStorage.getItem('deepinfra_api_key');
        if (storedKey) return storedKey;
        // Replace with your key. It's not recommended to hardcode keys in production.
        return 'lQL2CiM16FVMcSAVgpu1h9lrVXWlDzTI'; 
    }

    function log(message, type = 'info') {
        const timestamp = new Date().toLocaleTimeString();
        const emoji = type === 'success' ? '‚úÖ' : type === 'error' ? '‚ùå' : type === 'warning' ? '‚ö†Ô∏è' : '‚ö°';
        const logMessage = `${timestamp} ${emoji} ${message}`;
        console.log(logMessage);

        if (drawerDebug) {
            const newLine = document.createElement('div');
            newLine.textContent = logMessage;
            const typeClass = { error: 'text-red-300', success: 'text-green-300', warning: 'text-yellow-300' };
            newLine.className = typeClass[type] || '';
            drawerDebug.insertBefore(newLine, drawerDebug.firstChild);
            while (drawerDebug.children.length > 50) {
                drawerDebug.removeChild(drawerDebug.lastChild);
            }
        }
    }

    function updateStatus(text, iconName, stateClass) {
        if (!statusText || !voiceCircle) return;
        statusText.textContent = text;
        voiceCircle.innerHTML = `<i data-lucide="${iconName}" class="w-16 h-16 ${stateClass === 'processing' ? 'animate-spin' : ''}"></i>`;
        
        processingIndicator?.classList.toggle('opacity-100', stateClass === 'processing');
        
        let stateClasses = "";
        switch (stateClass) {
            case "listening": stateClasses = "bg-green-400/20 border-2 border-green-400/40 animate-pulse"; break;
            case "speaking": stateClasses = "bg-green-600/30 border-2 border-green-600/50"; break;
            case "processing": stateClasses = "bg-amber-400/20 border-2 border-amber-400/40"; break;
            case "tts-playing": stateClasses = "bg-purple-500/20 border-2 border-purple-500/40 animate-tts-pulse"; break;
            case "interrupted": stateClasses = "bg-red-500/20 border-2 border-red-500/40 animate-interrupt-flash"; break;
            default: stateClasses = "bg-white/10 border-2 border-white/20";
        }
        voiceCircle.className = `${baseCircleClasses} ${stateClasses}`;
        lucide.createIcons();
    }
    
    function updateButtonState() {
        if (!toggleButton || !toggleIconEl || !toggleText) return;
        
        toggleButton.disabled = recordingMode === 'continu' && (isPlaying || isProcessingTTS);

        if (recordingMode === 'push-to-talk') {
            const baseClass = "w-full py-4 rounded-2xl font-semibold text-base transition-all backdrop-blur-xl text-white flex items-center justify-center gap-2";
            if (isPushToTalkRecording) {
                toggleButton.className = `${baseClass} bg-red-500/80 hover:bg-red-600/80 animate-pulse`;
                toggleIconEl.setAttribute('data-lucide', 'square');
                toggleText.textContent = 'Send';
            } else if (isPlaying || isProcessingTTS) {
                toggleButton.className = `${baseClass} bg-orange-500/80 hover:bg-orange-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'square');
                toggleText.textContent = 'Interrupt';
            } else {
                toggleButton.className = `${baseClass} bg-blue-500/80 hover:bg-blue-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'mic');
                toggleText.textContent = 'Hold & Speak';
            }
        } else { // Continuous mode
            const baseClass = "w-full py-4 rounded-2xl font-semibold text-base transition-all backdrop-blur-xl text-white disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2";
            if (isContinuRecording) {
                toggleButton.className = `${baseClass} bg-red-500/80 hover:bg-red-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'mic-off');
                toggleText.textContent = 'Stop';
            } else {
                toggleButton.className = `${baseClass} bg-green-500/80 hover:bg-green-600/80`;
                toggleIconEl.setAttribute('data-lucide', 'mic');
                toggleText.textContent = 'Start';
            }
        }
        lucide.createIcons();
    }

    function updateModeButtons() {
        if (recordingMode === 'continu') {
            modeContinu.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-green-500/80 text-white";
            modePushToTalk.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-white/20 text-white/70 hover:bg-white/30";
        } else {
            modeContinu.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-white/20 text-white/70 hover:bg-white/30";
            modePushToTalk.className = "flex-1 py-2 px-3 rounded-lg text-sm font-medium transition-all bg-blue-500/80 text-white";
        }
    }
    
    // =============================================
    // üé§ RECORDING & VAD
    // =============================================
    async function requestMicrophonePermission() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            stream.getTracks().forEach(track => track.stop());
            log('Microphone permission granted', 'success');
            return true;
        } catch (error) {
            log('Microphone permission denied or unavailable.', 'error');
            alert('Please allow microphone access to use the voice assistant.');
            return false;
        }
    }

    async function toggleMasterRecording() {
        if (isContinuRecording || isPushToTalkRecording) {
            await stopAllRecording();
        } else {
            const hasPermission = await requestMicrophonePermission();
            if (!hasPermission) return;
            
            if (recordingMode === 'continu') await startContinuRecording();
            else await startPushToTalkRecording();
        }
    }
    async function togglePushToTalk() {
        if (isPlaying || isProcessingTTS) {
            interruptTTS();
            await new Promise(resolve => setTimeout(resolve, 100));
        }
        
        if (isPushToTalkRecording) {
            await stopPushToTalkRecording();
        } else {
            const hasPermission = await requestMicrophonePermission();
            if (hasPermission) await startPushToTalkRecording();
        }
    }
    async function startContinuRecording() {
        if (!drawerGroqKey.value.trim() || !drawerOpenaiKey.value.trim()) {
            alert('Please configure your API keys in the control panel.');
            return;
        }
        toggleButton.disabled = true;
        updateStatus("Initializing...", "loader-circle", "processing");

        try {
            await preGenerateSimpleReflections();
            myVad = await vad.MicVAD.new({
                positiveSpeechThreshold: 0.8, minSpeechFrames: 6, preSpeechPadFrames: 1, redemptionFrames: 10,
                onSpeechStart: () => {
                    log("Speech detected", 'success');
                    if (!interruptTTS()) updateStatus("You are speaking...", "mic", "speaking");
                },
                onSpeechEnd: (audio) => {
                    log(`End of speech`, 'info');
                    playRandomReflection();
                    if (!isProcessingTTS && audio.length > 100) transcribeAudioUltraFast(audio);
                    else if (myVad) updateStatus("Listening...", "mic", "listening");
                },
            });
            myVad.start();
            isContinuRecording = true;
            updateButtonState();
            updateStatus("Listening...", "mic", "listening");
            log("üé§ Continuous Mode started!", 'success');
        } catch (error) {
            log(`VAD Error: ${error.message}`, 'error');
            updateStatus("VAD Error", "alert-circle", "error");
            isContinuRecording = false;
        } finally {
            toggleButton.disabled = false;
            updateButtonState();
        }
    }

    async function startPushToTalkRecording() {
        if (!drawerGroqKey.value.trim() || !drawerOpenaiKey.value.trim()) {
            alert('Please configure your API keys in the control panel.');
            return;
        }

        updateStatus("Speak now...", "mic", "speaking");
        isPushToTalkRecording = true;
        updateButtonState();
        log("üé§ Push-to-Talk (direct) started", 'info');

        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            recordedChunks = [];

            mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
            mediaRecorder.ondataavailable = e => recordedChunks.push(e.data);
            mediaRecorder.onstop = async () => {
                const blob = new Blob(recordedChunks, { type: 'audio/webm' });
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await convertWebmToWavBuffer(arrayBuffer);
                await transcribeAudioUltraFast(audioBuffer);
            };
            mediaRecorder.start();
        } catch (error) {
            log(`Push-to-Talk Error: ${error.message}`, 'error');
            isPushToTalkRecording = false;
            updateButtonState();
        }
    }
    
    async function stopPushToTalkRecording() {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
            mediaRecorder.stop();
        }
        isPushToTalkRecording = false;
        updateButtonState();
        updateStatus("Processing...", "loader-circle", "processing");
    }

    async function stopAllRecording() {
        if (myVad) { myVad.destroy(); myVad = null; }
        await cleanupPipeline();
        
        reflectionAudios.forEach(URL.revokeObjectURL);
        reflectionAudios.clear();
        isPlayingReflection = false;
        
        isContinuRecording = false;
        isPushToTalkRecording = false;
        
        updateButtonState();
        updateStatus("Ready", "power-off", "");
        log("üõë Recording stopped", 'info');
    }

    function switchToMode(mode) {
        if (isContinuRecording || isPushToTalkRecording) {
            stopAllRecording();
        }
        recordingMode = mode;
        updateModeButtons();
        updateButtonState();
        log(`Switched mode to: ${mode}`, 'info');
    }

    // =============================================
    // üîä TTS & AUDIO PROCESSING
    // =============================================
    async function generateTTSForSentence(sentence, voice) {
        const cacheKey = `${voice}_${sentence}`;
        if (ttsCache.has(cacheKey)) return ttsCache.get(cacheKey);
        
        try {
            const payload = {
                text: sentence,
                exaggeration: parseFloat(document.getElementById('ttsExaggeration')?.value || 0.25),
                cfg: parseFloat(document.getElementById('ttsCfg')?.value || 0.5),
                temperature: parseFloat(document.getElementById('ttsTemperature')?.value || 0.7)
            };

            if (voice && voice !== 'default') {
                payload.voice_id = voice;
            }

            const response = await fetch('https://api.deepinfra.com/v1/inference/ResembleAI/chatterbox', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${getDeepInfraApiKey()}`
                },
                body: JSON.stringify(payload)
            });

            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }

            const contentType = response.headers.get('content-type');
            
            let audioBlob;
            if (contentType && contentType.includes('audio/')) {
                audioBlob = await response.blob();
            } else {
                const result = await response.json();
                if (result.audio) {
                    const base64Data = result.audio.replace(/^data:.*;base64,/, '');
                    const binaryString = atob(base64Data);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    audioBlob = new Blob([bytes], { type: 'audio/wav' });
                } else {
                    throw new Error('No audio data in response');
                }
            }

            const audioUrl = URL.createObjectURL(audioBlob);
            
            if (ttsCache.size >= MAX_CACHE_SIZE) {
                const [firstKey, firstUrl] = ttsCache.entries().next().value;
                URL.revokeObjectURL(firstUrl);
                ttsCache.delete(firstKey);
            }
            ttsCache.set(cacheKey, audioUrl);
            return audioUrl;
            
        } catch (error) {
            log(`‚ùå ResembleAI TTS Error: ${error.message}`, 'error');
            throw error;
        }
    }
    
    function analyzeAudioQuality(audioData) {
        const energy = audioData.reduce((s, x) => s + x * x, 0) / audioData.length;
        if (energy < 0.0008) { log('Audio too quiet', 'warning'); return false; }
        return true;
    }

    function encodeWAV(samples, sampleRate = 16000) {
        const buffer = new ArrayBuffer(44 + samples.length * 2);
        const view = new DataView(buffer);
        const writeString = (o, s) => { for (let i = 0; i < s.length; i++) view.setUint8(o + i, s.charCodeAt(i)); };
        writeString(0, 'RIFF'); view.setUint32(4, 36 + samples.length * 2, true); writeString(8, 'WAVE'); writeString(12, 'fmt ');
        view.setUint32(16, 16, true); view.setUint16(20, 1, true); view.setUint16(22, 1, true); view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true); view.setUint16(32, 2, true); view.setUint16(34, 16, true); writeString(36, 'data');
        view.setUint32(40, samples.length * 2, true);
        for (let i = 0; i < samples.length; i++) {
            view.setInt16(44 + i * 2, Math.max(-1, Math.min(1, samples[i])) * 0x7FFF, true);
        }
        return buffer;
    }

    async function convertWebmToWavBuffer(webmBuffer) {
        const audioCtx = new OfflineAudioContext(1, 48000 * 10, 48000);
        const audioBuffer = await audioCtx.decodeAudioData(webmBuffer);
        
        const samples = audioBuffer.getChannelData(0);
        return encodeWAV(samples, audioBuffer.sampleRate);
    }
    
    async function preGenerateSimpleReflections() {
        if (reflectionAudios.size > 0) return;
        log('üí≠ Pre-generating reflection audio...', 'info');
        const promises = SIMPLE_REFLECTIONS.map(async (phrase) => {
            try {
                const audioUrl = await generateTTSForSentence(phrase, drawerVoiceSelect.value, -1);
                reflectionAudios.set(phrase, audioUrl);
            } catch (error) { /* ignore */ }
        });
        await Promise.all(promises);
        log(`üéâ ${reflectionAudios.size} reflections ready!`, 'success');
    }

    function playRandomReflection() {
        if (isPlayingReflection || reflectionAudios.size === 0) return;
        const randomReflection = SIMPLE_REFLECTIONS[Math.floor(Math.random() * SIMPLE_REFLECTIONS.length)];
        const audioUrl = reflectionAudios.get(randomReflection);
        if (audioUrl) {
            isPlayingReflection = true;
            lastPlayedReflection = randomReflection;
            const reflectionAudio = new Audio(audioUrl);
            reflectionAudio.play().catch(e => log('Error playing reflection', 'error'));
            reflectionAudio.onended = () => { isPlayingReflection = false; };
        }
    }
    
    function splitIntoSentences(text) {
        return text.match(/[^.!?]+[.!?]*|[^.!?]+$/g)?.map(s => s.trim()).filter(s => s.length > 3) || [];
    }

    async function playAudioPipeline(sentences, voice) {
        for (let i = 0; i < sentences.length && pipelineActive; i++) {
            while (!readyAudioBuffer.has(i) && pipelineActive) await new Promise(r => setTimeout(r, 50));
            if (!pipelineActive) break;

            const audioData = readyAudioBuffer.get(i);
            readyAudioBuffer.delete(i);
            updateStatus(`AI Speaking... (${i + 1}/${sentences.length})`, "volume-2", "tts-playing");
            ttsAudio.src = audioData.audioUrl;

            await new Promise((resolve, reject) => {
                ttsAudio.onloadeddata = () => ttsAudio.play().catch(reject);
                ttsAudio.onended = resolve;
                ttsAudio.onerror = reject;
                if (!pipelineActive) resolve();
            });
        }
    }
    
    async function speakTextWithPipeline(text) {
        if (isProcessingTTS) return;
        isProcessingTTS = isPlaying = pipelineActive = true;
        updateButtonState();

        const sentences = splitIntoSentences(text);
        if (sentences.length === 0) { await cleanupPipeline(); return; }
        
        log(`üöÄ Starting TTS pipeline for ${sentences.length} sentences`, 'info');
        readyAudioBuffer.clear();
        generationWorkers = [];

        try {
            const worker = (async () => {
                for (let i = 0; i < sentences.length && pipelineActive; i++) {
                    if (readyAudioBuffer.size >= MAX_BUFFER_SIZE) {
                        await new Promise(r => setTimeout(r, 100)); i--; continue;
                    }
                    try {
                        const audioUrl = await generateTTSForSentence(sentences[i], drawerVoiceSelect.value);
                        if (pipelineActive) readyAudioBuffer.set(i, { audioUrl, sentence: sentences[i] });
                    } catch { /* ignore */ }
                }
            })();
            generationWorkers.push(worker);
            
            await playAudioPipeline(sentences, drawerVoiceSelect.value);
        } catch (error) {
            log(`Pipeline error: ${error.message}`, 'error');
        } finally {
            await cleanupPipeline();
        }
    }
    
    async function cleanupPipeline() {
        pipelineActive = false;
        isProcessingTTS = false;
        isPlaying = false;
        readyAudioBuffer.forEach(data => URL.revokeObjectURL(data.audioUrl));
        readyAudioBuffer.clear();
        await Promise.allSettled(generationWorkers);
        generationWorkers = [];
        updateButtonState();
        if (isContinuRecording) updateStatus("Listening...", "mic", "listening");
        else if (!isPushToTalkRecording) updateStatus("Ready", "power-off", "");
    }

    function interruptTTS() {
        if ((isPlaying || isProcessingTTS) && drawerAllowInterrupt.checked) {
            log('üõë TTS Interrupted!', 'warning');
            if (ttsAudio) { ttsAudio.pause(); ttsAudio.src = ""; }
            cleanupPipeline();
            updateStatus("Interrupted!", "zap-off", "interrupted");
            showInterruptIndicator();
            addToConversation('system', 'Response interrupted');
            setTimeout(() => {
                if(isContinuRecording) updateStatus("Listening...", "mic", "listening");
            }, 800);
            return true;
        }
        return false;
    }

    function showInterruptIndicator() {
        interruptIndicator?.classList.add('opacity-100');
        setTimeout(() => interruptIndicator?.classList.remove('opacity-100'), 1500);
    }

    // =============================================
    // üí¨ TRANSCRIPTION & LLM
    // =============================================
    async function transcribeAudioUltraFast(audioData) {
        if (recordingMode !== 'push-to-talk' && audioData instanceof Float32Array && !analyzeAudioQuality(audioData)) {
            updateStatus("Listening...", "mic", "listening"); return;
        }
        updateStatus("Transcribing...", "loader-circle", "processing");

        try {
            const wavBuffer = audioData instanceof ArrayBuffer ? audioData : encodeWAV(audioData);
            const formData = new FormData();
            formData.append('file', new Blob([wavBuffer], { type: 'audio/wav' }), 'audio.wav');
            formData.append('model', 'whisper-large-v3');
            // *** LANGUAGE CHANGED TO ENGLISH HERE ***
            formData.append('language', 'en');

            const response = await fetch('https://api.groq.com/openai/v1/audio/transcriptions', {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${drawerGroqKey.value}` },
                body: formData
            });
            if (!response.ok) throw new Error(`Transcription failed: ${response.statusText}`);
            const result = await response.json();
            const userText = result.text?.trim();
            
            // Filters for common English transcription artifacts can be added here
            const parasiteFilters = [/Subtitles by/i, /Transcribed by/i];
            if (!userText || parasiteFilters.some(f => f.test(userText))) {
                log('Empty or artifact transcription ignored.', 'warning');
                if (isContinuRecording) updateStatus("Listening...", "mic", "listening");
                else updateStatus("Ready", "power-off", "");
                return;
            }
            await processUserMessage(userText);
        } catch (error) {
            log(`Transcription error: ${error.message}`, 'error');
            if (isContinuRecording) updateStatus("Listening...", "mic", "listening");
            else updateStatus("Ready", "power-off", "");
        }
    }

    async function processUserMessage(userText) {
        if (!userText) return;
        addToConversation('user', userText);
        
        const aiResponse = await getLLMResponseStreaming(userText);
        if (aiResponse) {
            addToConversation('assistant', aiResponse);
            if (drawerAutoSpeak.checked) {
                speakTextWithPipeline(aiResponse);
            }
        }
        if (isContinuRecording && !isProcessingTTS) {
             updateStatus("Listening...", "mic", "listening");
        } else if (!isContinuRecording && !isPushToTalkRecording) {
            updateStatus("Ready", "power-off", "");
        }
    }

    async function getLLMResponseStreaming(userMessage) {
        log('üöÄ Requesting OpenAI GPT-4o Mini...', 'info');
        updateStatus("AI is thinking...", "brain-circuit", "processing");

        try {
            const messages = [
                // *** SYSTEM PROMPT CHANGED TO ENGLISH HERE ***
                { role: "system", content: "You are a natural, conversational voice assistant. Respond in spoken English, without emojis, asterisks, or formatting. Be concise (2-3 sentences max)." },
                ...conversationHistory.slice(-10),
                { role: 'user', content: userMessage }
            ];
            
            if (lastPlayedReflection) {
                messages.push({ role: "system", content: `CONTEXT: You just said "${lastPlayedReflection}". Don't repeat it. Continue the conversation naturally.` });
            }

            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${drawerOpenaiKey.value}`, 'Content-Type': 'application/json' },
                body: JSON.stringify({ model: 'gpt-4o-mini', messages, temperature: 0.5, max_tokens: 150, stream: true })
            });
            if (!response.ok) {
                const err = await response.json();
                throw new Error(err.error.message);
            }

            let fullResponse = '';
            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                const chunk = decoder.decode(value);
                const lines = chunk.split('\n');
                for (const line of lines) {
                    if (line.startsWith('data: ')) {
                        const data = line.slice(6);
                        if (data === '[DONE]') break;
                        try {
                            const parsed = JSON.parse(data);
                            fullResponse += parsed.choices[0]?.delta?.content || '';
                        } catch {}
                    }
                }
            }
            
            let cleanedResponse = fullResponse.trim();
            if (lastPlayedReflection && cleanedResponse.toLowerCase().startsWith(lastPlayedReflection.toLowerCase())) {
                cleanedResponse = cleanedResponse.substring(lastPlayedReflection.length).replace(/^[,.\s]+/, '');
            }
            lastPlayedReflection = "";
            log('‚úÖ OpenAI response received', 'success');
            return cleanedResponse;
        } catch (error) {
            log(`OpenAI Error: ${error.message}`, 'error');
            lastPlayedReflection = "";
            return `Sorry, an error occurred with the AI: ${error.message}`;
        }
    }

    // =============================================
    // üí¨ CONVERSATION UI
    // =============================================
    function addToConversation(type, content) {
        if (!conversationHistoryEl || !content) return;
        if (conversationHistoryEl.querySelector('.italic')) conversationHistoryEl.innerHTML = '';
        
        conversationHistory.push({ role: type, content });
        if(conversationHistory.length > 30) conversationHistory.shift();

        const div = document.createElement('div');
        const baseClasses = 'mb-3 px-4 py-3 rounded-2xl max-w-[85%] break-words shadow-md';
        let specificClasses = '';
        let header = '';

        if (type === 'user') {
            specificClasses = 'bg-blue-500 text-white ml-auto rounded-br-md';
            header = `<div class="text-xs opacity-80 mb-1">You</div>`;
        } else if (type === 'assistant') {
            specificClasses = 'bg-white/90 text-gray-800 mr-auto rounded-bl-md';
            const speakFn = `speakTextWithPipeline('${content.replace(/'/g, "\\'")}')`;
            header = `<div class="text-xs text-gray-600 opacity-70 mb-1 flex justify-between items-center"><span>Assistant</span><button onclick="${speakFn}" class="text-gray-600 hover:text-black transition-transform">üîä</button></div>`;
        } else { // System
             specificClasses = 'text-center text-xs text-white/50 italic w-full';
        }
        
        div.className = `${baseClasses} ${specificClasses}`;
        div.innerHTML = type === 'system' ? `--- ${content} ---` : `${header}<div>${content}</div>`;
        conversationHistoryEl.appendChild(div);
        conversationHistoryEl.scrollTop = conversationHistoryEl.scrollHeight;
    }
    
    // =============================================
    // üöÄ INITIALIZATION
    // =============================================
    window.onload = () => {
        // Assign DOM elements
        voiceCircle = document.getElementById('voice-circle');
        statusText = document.getElementById('status-text');
        toggleButton = document.getElementById('toggleButton');
        toggleIconEl = document.getElementById('toggleIconEl');
        toggleText = document.getElementById('toggleText');
        ttsAudio = document.getElementById('ttsAudio');
        interruptIndicator = document.getElementById('interrupt-indicator');
        processingIndicator = document.getElementById('processing-indicator');
        textInput = document.getElementById('text-input');
        sendButton = document.getElementById('send-button');
        modeContinu = document.getElementById('modeContinu');
        modePushToTalk = document.getElementById('modePushToTalk');
        conversationDrawer = document.getElementById('conversationDrawer');
        conversationHistoryEl = document.getElementById('conversationHistory');
        settingsDrawer = document.getElementById('settingsDrawer');
        drawerOverlay = document.getElementById('drawerOverlay');
        drawerGroqKey = document.getElementById('drawerGroqKey');
        drawerOpenaiKey = document.getElementById('drawerOpenaiKey');
        drawerDeepinfraKey = document.getElementById('drawerDeepinfraKey');
        drawerAutoSpeak = document.getElementById('drawerAutoSpeak');
        drawerAllowInterrupt = document.getElementById('drawerAllowInterrupt');
        drawerVoiceSelect = document.getElementById('drawerVoiceSelect');
        drawerDebug = document.getElementById('drawerDebug');
        ttsExaggeration = document.getElementById('ttsExaggeration');
        ttsCfg = document.getElementById('ttsCfg');
        ttsTemperature = document.getElementById('ttsTemperature');
        ttsExaggerationValue = document.getElementById('ttsExaggerationValue');
        ttsCfgValue = document.getElementById('ttsCfgValue');
        ttsTemperatureValue = document.getElementById('ttsTemperatureValue');

        // Initial state
        updateStatus("Ready to start", "power-off", "");
        updateButtonState();
        updateModeButtons();
        
        // Load saved settings
        drawerGroqKey.value = localStorage.getItem('groq_api_key') || '';
        drawerOpenaiKey.value = localStorage.getItem('openai_api_key') || '';
        drawerDeepinfraKey.value = localStorage.getItem('deepinfra_api_key') || '';
        drawerAutoSpeak.checked = localStorage.getItem('auto_speak') !== 'false';
        drawerAllowInterrupt.checked = localStorage.getItem('allow_interrupt') !== 'false';
        drawerVoiceSelect.value = localStorage.getItem('selected_voice') || 'default';

        // Attach event listeners
        toggleButton.onclick = () => {
             if (recordingMode === 'continu') toggleMasterRecording();
             else togglePushToTalk();
        };
        modeContinu.onclick = () => switchToMode('continu');
        modePushToTalk.onclick = () => switchToMode('push-to-talk');
        sendButton.onclick = () => processUserMessage(textInput.value.trim());
        textInput.onkeydown = (e) => { if (e.key === 'Enter') { e.preventDefault(); processUserMessage(textInput.value.trim()); textInput.value = ''; } };

        // Drawer functionality
        document.getElementById('conversationToggle').onclick = () => { conversationDrawer.classList.remove('-translate-x-full'); drawerOverlay.classList.remove('opacity-0', 'pointer-events-none'); };
        document.getElementById('drawerToggle').onclick = () => { settingsDrawer.classList.remove('translate-x-full'); drawerOverlay.classList.remove('opacity-0', 'pointer-events-none'); };
        const closeDrawers = () => {
            conversationDrawer.classList.add('-translate-x-full');
            settingsDrawer.classList.add('translate-x-full');
            drawerOverlay.classList.add('opacity-0', 'pointer-events-none');
        };
        document.getElementById('conversationDrawerClose').onclick = closeDrawers;
        document.getElementById('settingsDrawerClose').onclick = closeDrawers;
        drawerOverlay.onclick = closeDrawers;
        document.onkeydown = (e) => { if (e.key === 'Escape') closeDrawers(); };
        
        // Settings saving
        drawerGroqKey.oninput = () => localStorage.setItem('groq_api_key', drawerGroqKey.value);
        drawerOpenaiKey.oninput = () => localStorage.setItem('openai_api_key', drawerOpenaiKey.value);
        drawerDeepinfraKey.oninput = () => localStorage.setItem('deepinfra_api_key', drawerDeepinfraKey.value);
        drawerAutoSpeak.onchange = () => localStorage.setItem('auto_speak', drawerAutoSpeak.checked);
        drawerAllowInterrupt.onchange = () => localStorage.setItem('allow_interrupt', drawerAllowInterrupt.checked);
        drawerVoiceSelect.onchange = () => localStorage.setItem('selected_voice', drawerVoiceSelect.value);
        
        // TTS Slider listeners
        ttsExaggeration.oninput = () => { ttsExaggerationValue.textContent = ttsExaggeration.value; };
        ttsCfg.oninput = () => { ttsCfgValue.textContent = ttsCfg.value; };
        ttsTemperature.oninput = () => { ttsTemperatureValue.textContent = ttsTemperature.value; };
        
        // Drawer actions
        document.getElementById('drawerClearCache').onclick = () => {
            transcriptionCache.clear(); ttsCache.clear();
            log('Cache cleared', 'success');
        };
        document.getElementById('drawerExportConversation').onclick = () => {
            const data = JSON.stringify(conversationHistory, null, 2);
            const a = document.createElement('a');
            a.href = URL.createObjectURL(new Blob([data], { type: 'application/json' }));
            a.download = `conversation_${new Date().toISOString().slice(0,10)}.json`;
            a.click();
            URL.revokeObjectURL(a.href);
            log('Conversation exported', 'success');
        };
        
        // Update time
        const updateTime = () => { document.getElementById('time').textContent = new Date().toLocaleTimeString('en-US', { hour: '2-digit', minute: '2-digit' }); };
        updateTime();
        setInterval(updateTime, 10000);

        lucide.createIcons();
        log('üéØ System initialized successfully!', 'success');
        
        window.onbeforeunload = stopAllRecording;
    };
    </script>
</body>
</html>